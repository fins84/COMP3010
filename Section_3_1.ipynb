{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section_3_1\n",
        "\n",
        "This is the model with the accuracy of 83% (After target was reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c43HX435pQF9",
        "outputId": "924c7ba1-cb67-4daf-fe26-20058fa1c7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1+cu117)\n",
            "Requirement already satisfied: filelock in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2.8)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.2+cu117)\n",
            "Requirement already satisfied: numpy in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.1)\n",
            "Requirement already satisfied: requests in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.1)\n",
            "Requirement already satisfied: torch==2.0.1 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.0.1+cu117)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.1.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (4.4.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
            "Requirement already satisfied: torchsummary in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: skorch in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from skorch) (1.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from skorch) (1.8.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from skorch) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diamo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\diamo\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.14.0->skorch) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install torchsummary\n",
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubt0L3zUpSko",
        "outputId": "55d075fc-81af-404b-d3d3-a3bf3e8451b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import optimizer\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import gc\n",
        "import time\n",
        "import skorch\n",
        "\n",
        "#from d2l import torch as d2l\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure results are replicatable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x28a101176b0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Residual Block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7H2hPYfRpV5e"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, add, stride = 1, downsample = None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.add = add\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels))\n",
        "        if self.add:\n",
        "            self.added_layer = self.add_layer(out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def add_layer(self, planes):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.add:\n",
        "            out = self.added_layer(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out = out + residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "m8D39OhlpXxe"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, l1, l2, l3, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.Dropout = layers[4]\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        #nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU()\n",
        "                        )\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self._make_layer(block, 64, layers[0], 0, stride = 1)\n",
        "        self.layer1 = self._make_layer(block, 128, layers[1], l1, stride = 2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[2], l2, stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[3], l3, stride = 2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        #self.avgpool = nn.AvgPool2d(7,stride=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def _make_layer(self, block, planes, blocks, add_layer, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, add_layer, stride, downsample))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, add_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer0(x)\n",
        "        #x = self.drop1(x)\n",
        "        x = self.layer1(x)\n",
        "        #x = self.drop2(x)\n",
        "        x = self.layer2(x)\n",
        "        #x = self.drop3(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking Summary of Resnet Model with different input sizes and channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuJ26a_qrrUe",
        "outputId": "4afcedbb-0282-4572-dfa7-a2fce6c79cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,928\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,928\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "    ResidualBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "    ResidualBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,856\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,584\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,320\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "    ResidualBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,584\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,584\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "    ResidualBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         295,168\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         590,080\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          33,024\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "    ResidualBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         590,080\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         590,080\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "    ResidualBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,180,160\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,584\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "    ResidualBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "    ResidualBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,186,442\n",
            "Trainable params: 11,186,442\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.67\n",
            "Estimated Total Size (MB): 43.97\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = ResNet(ResidualBlock, [2,2,2,2,0.1], 0,0,0).to(device)\n",
        "summary(model, (3, 32, 32))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading CIFAR10 Dataset and applying tansforms on it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGeoETrjY6Ig",
        "outputId": "cc93a4e9-ab4c-4a7f-d261-6d97d78e1627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "imsize = 32\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((imsize,imsize), antialias=True),\n",
        "    #transforms.Grayscale(num_output_channels=1)\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "dataTrain = datasets.CIFAR10(\n",
        "    root=\"dataset\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "dataValid = datasets.CIFAR10(\n",
        "    root=\"dataset\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "\n",
        "print(len(dataValid[0][0]))\n",
        "\n",
        "valid_y = np.array([y for x,y in iter(dataValid)])\n",
        "test_y = np.array([y for x,y in iter(dataTrain)])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CNEepasRrtFi"
      },
      "source": [
        "Implementing Trainer: Static Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CLASStorch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, \n",
        "#weight_decay=0, nesterov=False, *, maximize=False, foreach=None, differentiable=False)\n",
        "def trainer(epochs, dataloader, model, lr, loader_valid, decay, mom ):\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=decay, momentum=mom)\n",
        "  scaler = torch.cuda.amp.GradScaler()\n",
        "  loss_f = nn.CrossEntropyLoss()\n",
        "  print(\"Epoch, Loss, Time, val_acc\")\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.perf_counter()\n",
        "    for x,y in dataloader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      with torch.cuda.amp.autocast():\n",
        "        pred = model(x)\n",
        "        loss = loss_f(pred, y)\n",
        "      optimizer.zero_grad()\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      pred = pred.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "      processed += len(x)\n",
        "\n",
        "      del x, y\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "    end = time.perf_counter()\n",
        "\n",
        "    train_acc = 100*(correct/processed)\n",
        "    acc = predict(model, loader_valid)\n",
        "    print(epoch + 1,\",\", loss.item(),\",\", end-start,\",\", acc, \",\", train_acc)\n",
        "\n",
        "\n",
        "def predict(model, loader_valid):\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x,y in loader_valid:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      output = model(x)\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "      del x,y,output\n",
        "  return 100*(correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decay: 0.015  LR: 0.04\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ResNet.__init__() missing 3 required positional arguments: 'l1', 'l2', and 'l3'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(decay)):\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDecay:\u001b[39m\u001b[39m\"\u001b[39m, decay[k], \u001b[39m\"\u001b[39m\u001b[39m LR:\u001b[39m\u001b[39m\"\u001b[39m, lr[j])\n\u001b[1;32m---> 16\u001b[0m     model \u001b[39m=\u001b[39m ResNet(ResidualBlock, [\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m,Dropout])\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m     trainer(epochs ,loader_train ,model, lr[j], loader_valid, decay[k], mom)\n",
            "\u001b[1;31mTypeError\u001b[0m: ResNet.__init__() missing 3 required positional arguments: 'l1', 'l2', and 'l3'"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "num_w = [2]\n",
        "lr = [0.04]\n",
        "Dropout = 0.0\n",
        "b_size = 4500\n",
        "mom = 0.5\n",
        "decay = [0.015]\n",
        "\n",
        "for i in range(0,len(num_w)):\n",
        "    loader_train = DataLoader(dataTrain, batch_size=b_size, shuffle=True, num_workers=num_w[i])\n",
        "    loader_valid = DataLoader(dataValid, batch_size=b_size, shuffle=True, num_workers=num_w[i])\n",
        "\n",
        "    for j in range(0, len(lr)):\n",
        "        for k in range(0, len(decay)):\n",
        "            print(\"Decay:\", decay[k], \" LR:\", lr[j])\n",
        "            model = ResNet(ResidualBlock, [2,2,2,2,Dropout], 0, 0, 0).to(device)\n",
        "            trainer(epochs ,loader_train ,model, lr[j], loader_valid, decay[k], mom)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing Trainer: Learning Rate Scheduler Version (What Im using for final model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainer(epochs, dataloader, model, lr, loader_valid, decay, mom, batch):\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=decay, momentum=mom)\n",
        "  #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=lr, steps_per_epoch=((50000//batch) + 1), epochs=epochs,anneal_strategy='linear')\n",
        "  scaler = torch.cuda.amp.GradScaler()\n",
        "  loss_f = nn.CrossEntropyLoss()\n",
        "  print(\"Epoch, Loss, Time, val acc, train acc\")\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.perf_counter()\n",
        "    for x,y in dataloader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      with torch.cuda.amp.autocast():\n",
        "        pred = model(x)\n",
        "        loss = loss_f(pred, y)\n",
        "      optimizer.zero_grad()\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "      scheduler.step()\n",
        "      #print(scheduler.get_last_lr())\n",
        "\n",
        "      pred = pred.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "      processed += len(x)\n",
        "\n",
        "      del x, y\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "    end = time.perf_counter()\n",
        "\n",
        "    train_acc = 100*(correct/processed)\n",
        "    acc = predict(model, loader_valid, loss_f,scheduler)\n",
        "    print(epoch + 1,\",\", loss.item(),\",\", end-start,\",\", acc, \",\", train_acc)\n",
        "\n",
        "\n",
        "def predict(model, loader_valid, loss_f,scheduler):\n",
        "  with torch.no_grad():\n",
        "    #t_loss=0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x,y in loader_valid:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      output = model(x)\n",
        "      loss = loss_f(output, y)\n",
        "      #t_loss += loss.item()\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "      del x,y,output\n",
        "    #scheduler.step(t_loss)\n",
        "  return 100*(correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decay: 0.01  LR: 0.075\n",
            "Epoch, Loss, Time, val acc, train acc\n",
            "1 , 1.2892842292785645 , 11.680418000003556 , 52.059999999999995 , 40.756\n",
            "2 , 1.1088640689849854 , 11.553782500006491 , 59.98 , 48.649\n",
            "3 , 0.9654399752616882 , 11.179152800003067 , 64.57000000000001 , 53.715999999999994\n",
            "4 , 0.8501710891723633 , 11.661519400018733 , 67.44 , 57.01500000000001\n",
            "5 , 0.8359678983688354 , 11.30753249998088 , 70.3 , 59.6316\n",
            "6 , 0.8306155204772949 , 11.540755800000625 , 70.14 , 61.608666666666664\n",
            "7 , 0.7208300232887268 , 11.295407099998556 , 72.82 , 63.242\n",
            "8 , 0.6891565918922424 , 11.493630199984182 , 72.25 , 64.704\n",
            "9 , 0.6642736196517944 , 11.305872500000987 , 72.45 , 66.05711111111111\n",
            "10 , 0.6936509013175964 , 11.769682500016643 , 74.03 , 67.2372\n",
            "11 , 0.6528723835945129 , 11.46218519998365 , 74.7 , 68.25509090909091\n",
            "12 , 0.5880341529846191 , 11.442603900009999 , 75.35 , 69.229\n",
            "13 , 0.5849801301956177 , 11.515507600008277 , 77.22 , 70.12076923076923\n",
            "14 , 0.5780685544013977 , 11.508912699995562 , 77.02 , 70.959\n",
            "15 , 0.5153763890266418 , 11.748361400008434 , 76.88000000000001 , 71.75146666666666\n",
            "16 , 0.5341936945915222 , 12.33819029998267 , 78.84 , 72.54025\n",
            "17 , 0.44773098826408386 , 11.743552700005239 , 79.59 , 73.31741176470588\n",
            "18 , 0.3530701994895935 , 11.526622000004863 , 80.47999999999999 , 74.1451111111111\n",
            "19 , 0.2657836079597473 , 11.56615349999629 , 81.63 , 75.01873684210526\n",
            "20 , 0.1941281110048294 , 12.19861559997662 , 82.67999999999999 , 75.9923\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "num_w = 2\n",
        "lr = [0.075]\n",
        "Dropout = 0.0\n",
        "b_size = [1024]\n",
        "mom = 0.5\n",
        "decay = [0.01]\n",
        "\n",
        "for i in range(0,len(b_size)):\n",
        "    loader_train = DataLoader(dataTrain, batch_size=b_size[i], shuffle=True, num_workers=num_w)\n",
        "    loader_valid = DataLoader(dataValid, batch_size=b_size[i], shuffle=True, num_workers=num_w)\n",
        "\n",
        "    for j in range(0, len(lr)):\n",
        "        for k in range(0, len(decay)):\n",
        "            print(\"Decay:\", decay[k], \" LR:\", lr[j])\n",
        "            model = ResNet(ResidualBlock, [2,2,2,2,Dropout], 0,0,0).to(device)\n",
        "            trainer(epochs ,loader_train ,model, lr[j], loader_valid, decay[k], mom, b_size[i])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CZxb54KDw6UA"
      },
      "source": [
        "Refernces:\n",
        "\n",
        "https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/ \n",
        "\n",
        "https://appsilon.com/pytorch-neural-network-tutorial/\n",
        "\n",
        "https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/#:~:text=CNN%20Dropout%20Regularization,is%20just%20a%20rough%20heuristic.&text=In%20this%20case%2C%20dropout%20is,cell%20within%20the%20feature%20maps. - dropout\n",
        "\n",
        "https://www.kaggle.com/code/greatcodes/pytorch-cnn-resnet18-cifar10/notebook \n",
        "\n",
        "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863 - lr scheduler"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
